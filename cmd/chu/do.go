package main

import (
	"context"
	"fmt"
	"os"
	"strings"
	"time"

	"github.com/spf13/cobra"

	"chuchu/internal/config"
	"chuchu/internal/intelligence"
	"chuchu/internal/llm"
	"chuchu/internal/modes"
)

var doCmd = &cobra.Command{
	Use:   "do [task]",
	Short: "Execute a task autonomously",
	Long: `Execute a task autonomously using the agent system.

Examples:
  chu do "add error handling to main.go"
  chu do "read docs/README.md and create a getting-started guide"
  chu do "unify all feature files in /guides"`,
	Args: cobra.MinimumNArgs(1),
	RunE: func(cmd *cobra.Command, args []string) error {
		task := strings.Join(args, " ")

		dryRun, _ := cmd.Flags().GetBool("dry-run")
		verbose, _ := cmd.Flags().GetBool("verbose")
		maxAttempts, _ := cmd.Flags().GetInt("max-attempts")
		supervised, _ := cmd.Flags().GetBool("supervised")
		interactive, _ := cmd.Flags().GetBool("interactive")

		if verbose {
			fmt.Fprintf(os.Stderr, "Task: %s\n", task)
			fmt.Fprintf(os.Stderr, "Dry-run: %v\n", dryRun)
			fmt.Fprintf(os.Stderr, "Max attempts: %d\n\n", maxAttempts)
		}

		if dryRun {
			return runDoAnalysis(task, verbose)
		}

		return runDoExecutionWithRetry(task, verbose, maxAttempts, supervised, interactive)
	},
}

func init() {
	rootCmd.AddCommand(doCmd)

	doCmd.Flags().Bool("dry-run", false, "Show analysis and plan without executing")
	doCmd.Flags().BoolP("verbose", "v", false, "Show detailed progress")
	doCmd.Flags().Int("max-attempts", 3, "Maximum retry attempts with different models")
	doCmd.Flags().Bool("supervised", false, "Require manual approval before implementation")
	doCmd.Flags().BoolP("interactive", "i", false, "Prompt for model selection when multiple options are similar")
}

func runDoAnalysis(task string, verbose bool) error {
	setup, err := config.LoadSetup()
	if err != nil {
		return fmt.Errorf("failed to load setup: %w", err)
	}

	backendName := setup.Defaults.Backend
	backendCfg := setup.Backend[backendName]

	var provider llm.Provider
	if backendCfg.Type == "ollama" {
		provider = llm.NewOllama(backendCfg.BaseURL)
	} else {
		provider = llm.NewChatCompletion(backendCfg.BaseURL, backendName)
	}

	queryModel := backendCfg.GetModelForAgent("query")

	fmt.Println("=== Task Analysis ===")
	fmt.Printf("Task: %s\n\n", task)

	analysisPrompt := fmt.Sprintf(`Analyze this task and determine:
1. Primary intent (create, read, update, refactor, unify, etc.)
2. Files that need to be read (if any)
3. Files that will be created or modified
4. Key steps required
5. Estimated complexity (1-10)

Task: %s

Provide a brief analysis.`, task)

	resp, err := provider.Chat(context.Background(), llm.ChatRequest{
		SystemPrompt: "You analyze tasks to determine requirements and complexity.",
		UserPrompt:   analysisPrompt,
		Model:        queryModel,
	})
	if err != nil {
		return fmt.Errorf("analysis failed: %w", err)
	}

	fmt.Println(resp.Text)
	fmt.Println("\n=== Execution Plan ===")
	fmt.Println("This would create a detailed plan and execute using guided mode.")
	fmt.Println("\nTo execute: run without --dry-run flag")

	return nil
}

func runDoExecutionWithRetry(task string, verbose bool, maxAttempts int, supervised bool, interactive bool) error {
	setup, err := config.LoadSetup()
	if err != nil {
		return fmt.Errorf("failed to load setup: %w", err)
	}

	editorBackend, editorModel, editorReason, err := intelligence.SelectBestModelForAgent(setup, "editor")
	if err != nil {
		editorBackend = setup.Defaults.Backend
		backendCfg := setup.Backend[editorBackend]
		editorModel = backendCfg.GetModelForAgent("editor")
		editorReason = "Fallback to default"
	}

	queryBackend, queryModel, queryReason, err := intelligence.SelectBestModelForAgent(setup, "query")
	if err != nil {
		queryBackend = setup.Defaults.Backend
		backendCfg := setup.Backend[queryBackend]
		queryModel = backendCfg.GetModelForAgent("query")
		queryReason = "Fallback to default"
	}

	if verbose {
		fmt.Fprintf(os.Stderr, "ü§ñ Auto-selected models:\n")
		fmt.Fprintf(os.Stderr, "   Editor: %s/%s - %s\n", editorBackend, editorModel, editorReason)
		fmt.Fprintf(os.Stderr, "   Query: %s/%s - %s\n", queryBackend, queryModel, queryReason)
		fmt.Fprintf(os.Stderr, "\n")
	}

	currentBackend := editorBackend
	currentEditorModel := editorModel

	for attempt := 1; attempt <= maxAttempts; attempt++ {
		if attempt > 1 && verbose {
			fmt.Fprintf(os.Stderr, "\n=== Attempt %d/%d ===\n", attempt, maxAttempts)
		}

		startTime := time.Now()
		err := runDoExecution(task, verbose, supervised, setup, currentBackend, currentEditorModel)
		elapsed := time.Since(startTime).Milliseconds()

		if err == nil {
			_ = intelligence.RecordExecution(intelligence.TaskExecution{
				Task:      task,
				Backend:   currentBackend,
				Model:     currentEditorModel,
				Success:   true,
				LatencyMs: elapsed,
			})

			if verbose {
				fmt.Fprintf(os.Stderr, "\n‚úì Task completed successfully\n")
			}
			return nil
		}

		_ = intelligence.RecordExecution(intelligence.TaskExecution{
			Task:    task,
			Backend: currentBackend,
			Model:   currentEditorModel,
			Success: false,
			Error:   err.Error(),
		})

		errMsg := err.Error()
		looksLikeToolError := strings.Contains(errMsg, "tool") || strings.Contains(errMsg, "function") ||
			strings.Contains(errMsg, "not available") || strings.Contains(errMsg, "not supported")

		if !looksLikeToolError {
			return fmt.Errorf("task failed: %w", err)
		}

		if attempt >= maxAttempts {
			return fmt.Errorf("task failed after %d attempts: %w", maxAttempts, err)
		}

		if verbose {
			fmt.Fprintf(os.Stderr, "\n‚ùå Attempt %d failed: %v\n", attempt, err)
			fmt.Fprintf(os.Stderr, "ü§î Asking intelligence system for alternative model...\n")
		}

		recommendations, err := intelligence.RecommendModelForRetry(setup, "editor", currentBackend, currentEditorModel, task)
		if err != nil || len(recommendations) == 0 {
			return fmt.Errorf("no alternative models available: %w", err)
		}

		rec := recommendations[0]

		if verbose {
			fmt.Fprintf(os.Stderr, "\nüí° Intelligence recommends: %s/%s\n", rec.Backend, rec.Model)
			fmt.Fprintf(os.Stderr, "   Overall Score: %.2f\n", rec.Score)
			fmt.Fprintf(os.Stderr, "   Success Rate: %.0f%% | Speed: %d TPS | Cost: $%.3f/1M | Latency: %dms\n",
				rec.Metrics.SuccessRate*100,
				rec.Metrics.SpeedTPS,
				rec.Metrics.CostPer1M,
				rec.Metrics.AvgLatencyMs)
			fmt.Fprintf(os.Stderr, "   Reason: %s\n", rec.Reason)
			fmt.Fprintf(os.Stderr, "\nüîÑ Retrying with recommended model...\n")
		}

		if rec.Backend != currentBackend {
			if _, exists := setup.Backend[rec.Backend]; exists {
				currentBackend = rec.Backend
			}
		}

		currentEditorModel = rec.Model
	}

	return fmt.Errorf("task failed after %d attempts", maxAttempts)
}

func runDoExecution(task string, verbose bool, supervised bool, setup *config.Setup, backendName string, editorModel string) error {
	backendCfg := setup.Backend[backendName]

	cwd, _ := os.Getwd()

	var provider llm.Provider
	if backendCfg.Type == "ollama" {
		provider = llm.NewOllama(backendCfg.BaseURL)
	} else {
		provider = llm.NewChatCompletion(backendCfg.BaseURL, backendName)
	}

	researchModel := backendCfg.GetModelForAgent("research")
	orchestrator := llm.NewOrchestrator(backendCfg.BaseURL, backendName, provider, researchModel)

	queryModel := backendCfg.GetModelForAgent("query")

	if verbose {
		fmt.Fprintf(os.Stderr, "Backend: %s\n", backendName)
		fmt.Fprintf(os.Stderr, "Editor Model: %s\n", editorModel)
		fmt.Fprintf(os.Stderr, "Query Model: %s\n\n", queryModel)
	}

	// ALWAYS use Symphony executor for non-supervised mode
	// Symphony internally decides: complexity < 7 = direct, >= 7 = decompose
	if !supervised {
		if verbose {
			fmt.Fprintf(os.Stderr, "üîç Analyzing task complexity...\n")
		}
		executor := modes.NewAutonomousExecutor(orchestrator, provider, cwd, queryModel, editorModel)
		return executor.Execute(context.Background(), task)
	}

	// Supervised mode: use guided workflow
	if supervised {
		guided := modes.NewGuidedMode(orchestrator, cwd, queryModel)

		if verbose {
			fmt.Fprintf(os.Stderr, "Creating plan...\n")
		}

		planContent, err := guided.ExecuteAndReturnPlan(context.Background(), task)
		if err != nil {
			return fmt.Errorf("plan creation failed: %w", err)
		}

		if verbose {
			fmt.Fprintf(os.Stderr, "Plan created. Starting implementation...\n")
		}

		guidedWithCustomEditor := modes.NewGuidedModeWithCustomModel(orchestrator, provider, cwd, queryModel, editorModel)

		if err := guidedWithCustomEditor.Implement(context.Background(), planContent); err != nil {
			return fmt.Errorf("implementation failed: %w", err)
		}
	} else {
		orchestrated := modes.NewOrchestratedMode(orchestrator, provider, cwd, queryModel, editorModel)

		if verbose {
			fmt.Fprintf(os.Stderr, "Using orchestrated mode with decomposed agents...\n")
		}

		if err := orchestrated.Execute(context.Background(), task); err != nil {
			return fmt.Errorf("orchestrated execution failed: %w", err)
		}
	}

	return nil
}
