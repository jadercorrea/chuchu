package main

import (
	"encoding/json"
	"fmt"
	"os"
	"path/filepath"
	"time"
)

type ModelInput struct {
	ID                    string   `json:"id"`
	Name                  string   `json:"name"`
	Tags                  []string `json:"tags"`
	RecommendedFor        []string `json:"recommended_for"`
	ContextWindow         int      `json:"context_window"`
	PricingPrompt         float64  `json:"pricing_prompt_per_m_tokens"`
	PricingComp           float64  `json:"pricing_completion_per_m_tokens"`
	Installed             bool     `json:"installed"`
}

type ProviderInput struct {
	Models []ModelInput `json:"models"`
}

type CatalogInput struct {
	Groq       ProviderInput `json:"groq"`
	OpenRouter ProviderInput `json:"openrouter"`
	Ollama     ProviderInput `json:"ollama"`
	OpenAI     ProviderInput `json:"openai"`
	DeepSeek   ProviderInput `json:"deepseek"`
}

type Benchmarks struct {
	HumanEval float64 `json:"humaneval"`
	SWEBench  float64 `json:"swe_bench"`
	LiveCode  float64 `json:"livecode"`
	AIME      float64 `json:"aime"`
}

type ModelOutput struct {
	ID                string     `json:"id"`
	Name              string     `json:"name"`
	Provider          string     `json:"provider"`
	Family            string     `json:"family"`
	Parameters        string     `json:"parameters"`
	ContextWindow     int        `json:"context_window"`
	PricingPrompt     float64    `json:"pricing_prompt_per_m_tokens"`
	PricingComp       float64    `json:"pricing_completion_per_m_tokens"`
	SpeedTokensPerSec int        `json:"speed_tokens_per_sec"`
	Benchmarks        Benchmarks `json:"benchmarks"`
	Tags              []string   `json:"tags"`
	RecommendedFor    []string   `json:"recommended_for"`
	SupportsTools     bool       `json:"supports_tools"`
	SupportsJSON      bool       `json:"supports_json"`
	ReleasedAt        string     `json:"released_at,omitempty"`
	Installed         bool       `json:"installed,omitempty"`
}

type Metadata struct {
	GeneratedAt    string              `json:"generated_at"`
	Version        string              `json:"version"`
	TotalModels    int                 `json:"total_models"`
	Sources        []string            `json:"sources"`
	BenchmarksInfo map[string]string   `json:"benchmarks_info"`
}

type OutputJSON struct {
	Models   []ModelOutput `json:"models"`
	Metadata Metadata      `json:"metadata"`
}

var benchmarkData = map[string]Benchmarks{
	"groq/llama-3.3-70b-versatile": {HumanEval: 82.4, SWEBench: 38.2, LiveCode: 75.1, AIME: 70.5},
	"groq/llama-3.1-8b-instant": {HumanEval: 72.6, SWEBench: 25.7, LiveCode: 58.3, AIME: 48.2},
	"openrouter/anthropic/claude-4.5-sonnet": {HumanEval: 92.0, SWEBench: 49.0, LiveCode: 88.6, AIME: 88.7},
	"openrouter/openai/gpt-4o": {HumanEval: 90.2, SWEBench: 48.9, LiveCode: 85.4, AIME: 83.3},
	"openrouter/google/gemini-2.0-flash-exp:free": {HumanEval: 71.9, SWEBench: 28.3, LiveCode: 62.1, AIME: 58.0},
	"ollama/qwen2.5-coder:7b": {HumanEval: 88.0, SWEBench: 35.2, LiveCode: 70.8, AIME: 55.4},
	"openrouter/deepseek/deepseek-chat": {HumanEval: 84.1, SWEBench: 40.6, LiveCode: 73.2, AIME: 65.7},
	"openrouter/x-ai/grok-beta": {HumanEval: 87.5, SWEBench: 43.8, LiveCode: 78.9, AIME: 74.2},
}

var speedData = map[string]int{
	"groq/llama-3.3-70b-versatile": 500,
	"groq/llama-3.1-8b-instant": 800,
	"openrouter/anthropic/claude-4.5-sonnet": 85,
	"openrouter/openai/gpt-4o": 120,
	"openrouter/google/gemini-2.0-flash-exp:free": 200,
	"ollama/qwen2.5-coder:7b": 45,
	"openrouter/deepseek/deepseek-chat": 180,
	"openrouter/x-ai/grok-beta": 150,
}

func main() {
	home, err := os.UserHomeDir()
	if err != nil {
		fmt.Fprintf(os.Stderr, "Failed to get home directory: %v\n", err)
		os.Exit(1)
	}

	inputPath := filepath.Join(home, ".chuchu", "models.json")
	data, err := os.ReadFile(inputPath)
	if err != nil {
		fmt.Fprintf(os.Stderr, "Failed to read %s: %v\n", inputPath, err)
		os.Exit(1)
	}

	var catalog CatalogInput
	if err := json.Unmarshal(data, &catalog); err != nil {
		fmt.Fprintf(os.Stderr, "Failed to parse JSON: %v\n", err)
		os.Exit(1)
	}

	var allModels []ModelOutput

	for _, provider := range []struct {
		name   string
		models []ModelInput
	}{
		{"groq", catalog.Groq.Models},
		{"openrouter", catalog.OpenRouter.Models},
		{"ollama", catalog.Ollama.Models},
		{"openai", catalog.OpenAI.Models},
		{"deepseek", catalog.DeepSeek.Models},
	} {
		for _, model := range provider.models {
			output := ModelOutput{
				ID:             model.ID,
				Name:           model.Name,
				Provider:       provider.name,
				Family:         extractFamily(model.Name),
				Parameters:     extractParameters(model.Name),
				ContextWindow:  model.ContextWindow,
				PricingPrompt:  model.PricingPrompt,
				PricingComp:    model.PricingComp,
				Tags:           model.Tags,
				RecommendedFor: model.RecommendedFor,
				SupportsTools:  true,
				SupportsJSON:   true,
				Installed:      model.Installed,
			}

			if benchmarks, ok := benchmarkData[model.ID]; ok {
				output.Benchmarks = benchmarks
			}

			if speed, ok := speedData[model.ID]; ok {
				output.SpeedTokensPerSec = speed
			} else {
				output.SpeedTokensPerSec = estimateSpeed(provider.name, model.PricingPrompt)
			}

			allModels = append(allModels, output)
		}
	}

	outputData := OutputJSON{
		Models: allModels,
		Metadata: Metadata{
			GeneratedAt: time.Now().UTC().Format(time.RFC3339),
			Version:     "1.0.0",
			TotalModels: len(allModels),
			Sources: []string{
				"OpenRouter API",
				"Groq API",
				"Ollama Library",
				"HumanEval public benchmarks",
				"LiveCodeBench leaderboard",
				"SWE-Bench leaderboard",
				"AIME results",
			},
			BenchmarksInfo: map[string]string{
				"humaneval": "Code completion accuracy (0-100)",
				"swe_bench": "Real bug fixing success rate (0-100)",
				"livecode":  "Competitive programming (0-100)",
				"aime":      "Math and logic for coding (0-100)",
			},
		},
	}

	outputPath := "docs/compare/data/models.json"
	jsonData, err := json.MarshalIndent(outputData, "", "  ")
	if err != nil {
		fmt.Fprintf(os.Stderr, "Failed to marshal JSON: %v\n", err)
		os.Exit(1)
	}

	if err := os.WriteFile(outputPath, jsonData, 0644); err != nil {
		fmt.Fprintf(os.Stderr, "Failed to write %s: %v\n", outputPath, err)
		os.Exit(1)
	}

	fmt.Printf("Successfully exported %d models to %s\n", len(allModels), outputPath)
}

func extractFamily(name string) string {
	name = toLower(name)
	if contains(name, "llama") {
		return "llama"
	}
	if contains(name, "claude") {
		return "claude"
	}
	if contains(name, "gpt") {
		return "gpt"
	}
	if contains(name, "gemini") {
		return "gemini"
	}
	if contains(name, "qwen") {
		return "qwen"
	}
	if contains(name, "deepseek") {
		return "deepseek"
	}
	if contains(name, "grok") {
		return "grok"
	}
	return "unknown"
}

func extractParameters(name string) string {
	if contains(name, "70b") || contains(name, "70B") {
		return "70B"
	}
	if contains(name, "8b") || contains(name, "8B") {
		return "8B"
	}
	if contains(name, "7b") || contains(name, "7B") {
		return "7B"
	}
	if contains(name, "67b") || contains(name, "67B") {
		return "67B"
	}
	return "Unknown"
}

func estimateSpeed(provider string, pricing float64) int {
	switch provider {
	case "groq":
		return 500
	case "ollama":
		return 50
	case "openrouter":
		if pricing < 1.0 {
			return 150
		}
		return 100
	default:
		return 100
	}
}

func contains(s, substr string) bool {
	return len(s) >= len(substr) && indexOfSubstring(s, substr) >= 0
}

func indexOfSubstring(s, substr string) int {
	for i := 0; i <= len(s)-len(substr); i++ {
		if s[i:i+len(substr)] == substr {
			return i
		}
	}
	return -1
}

func toLower(s string) string {
	result := make([]byte, len(s))
	for i := 0; i < len(s); i++ {
		c := s[i]
		if c >= 'A' && c <= 'Z' {
			result[i] = c + 32
		} else {
			result[i] = c
		}
	}
	return string(result)
}
